{"name":"Logist","tagline":"Easy logging for humans and machines","body":"Logist\r\n------\r\n\r\nEasy logging for humans and machines\r\n \r\n```logging``` in standard library is wonderful. But if you want \r\nsomething simpler, ready-to-use and blazing fast, ```Logist``` is for you! \r\nLogist is a redis backed logging system with a performance of \r\n6000 logs/second.\r\n \r\n \r\n## Documentation\r\n\r\n### Installation\r\n\r\n```bash\r\npip install logist\r\n```\r\n    \r\n### Basic Usage\r\n\r\n```python\r\nfrom logist import Logist\r\nlogger = Logist()\r\nlogger.log(log_type, sub_type, description, log_time)\r\n```\r\n\r\n**log_type:** type of log - ERROR, WARNING, SUCCESS, INFO, DEBUG\r\n\r\n**sub_type:** custom log sub types for easy tracking \r\n- Eg: ACCESS, WRITE, READ, EDIT, DELETE\r\n\r\n**description:** brief log description\r\n\r\n**log_time:** time of the logging - else auto populate\r\n\r\n\r\n## Specific Functions\r\n\r\n#### Success\r\n```python\r\nlogger.success(\"API_LOOKUP\", \"20301 bytes of json data served\")\r\n```\r\n\r\n#### Warning\r\n```python\r\nlogger.warning(\"API_LOOKUP\", \"301 bytes of json data served\")\r\n```\r\n\r\n#### Info\r\n```python\r\nlogger.info(\"API_LOOKUP\", \"20301 bytes of json data served\")\r\n```\r\n\r\n#### Error\r\n```python\r\nlogger.error(\"API_LOOKUP_ERROR\", \"0 bytes of json data served\")\r\n```\r\n\r\n#### Debug\r\n```python\r\nlogger.debug(\"API_LOOKUP_DEBUG\", \"2301 bytes of csv data served\")\r\n```\r\n\r\n\r\n\r\n## Configuration Options\r\n\r\n\r\nREDIS_ADDRESS: Address to redis server\r\n\r\nREDIS_PORT: redis server port\r\n\r\nFLUSH_COUNT: log count when in-memory logs to be flushed to file\r\n\r\nFILE_SIZE: file size when log file to be split up and compressed\r\n\r\nLOG_FILE_NAME: name of the log file\r\n\r\nLOG_FOLDER: folder for log files\r\n\r\nNAMESPACE: a custom namespace for logs to be kept in redis server\r\n\r\nCOMPRESSION: a boolean field to enable/disable compression (True/False)\r\n\r\n\r\nEither, create a configuration file with name ```logist_config.json``` \r\nin the pwd, like below\r\n\r\n```json\r\n{\r\n    \"REDIS_ADDRESS\": \"localhost\",\r\n    \"REDIS_PORT\": 6379,\r\n    \"FLUSH_COUNT\": 10000,\r\n    \"FILE_SIZE\": 10000000,\r\n    \"LOG_FILE_NAME\": \"\",\r\n    \"LOG_FOLDER\": \"\",\r\n    \"NAMESPACE\": \"PROJECT_NAME\",\r\n    \"COMPRESSION\": true\r\n}\r\n```\r\n\r\nor\r\n\r\ncreate Logist objects with custom configuration options required \r\nas shown below\r\n\r\n```python\r\nlogger = Logist(redis_address=\"localhost\", redis_port=6379, \r\n    flush_count=10000, file_size=10000000,\r\n    log_file_name=\"default\", log_folder=\"\", \r\n    namespace=\"DEFAULT\", compression=True)\r\n```\r\n\r\n## Advanced Features\r\n\r\n#### Filter\r\n\r\nAdvanced feature to filter logs as required based on log_type, \r\nsub_type, description and log_location. force_refresh is used to \r\nreload the index from the source file/memory\r\n\r\n```python\r\nlogger.filter(log_source=\"memory\", date_from=\"\", date_to=\"\", \r\n    log_type=\"\", sub_type=\"\", description=\"\", force_refresh=False)\r\n```\r\nMatches if ```description```, ```log_type``` and ```sub_type``` \r\ncontains the particular string. ```date_from``` and ```date_to``` \r\nare datetime objects for filtering\r\n\r\n#### Count\r\n\r\nAdvanced feature to filter logs as required based on log_type, \r\nsub_type, description and log_location. force_refresh is used to \r\nreload the index from the source file/memory\r\n\r\n```python\r\nlogger.count(log_source=\"memory\", date_from=\"\", date_to=\"\", log_type=\"\", \r\n    sub_type=\"\", description=\"\", log_location=\"memory\", force_refresh=False)\r\n```","google":"UA-72226457-1","note":"Don't delete this file! It's used internally to help with page regeneration."}